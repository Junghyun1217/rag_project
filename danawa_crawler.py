from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains 
from webdriver_manager.chrome import ChromeDriverManager
import time
import json
import random

# --- ë‹¤ë‚˜ì™€ ìŠ¤í¬ë˜í•‘ ì„¤ì • ë³€ìˆ˜ (ê²Œì´ë° ë…¸íŠ¸ë¶) ---
BASE_SEARCH_URL = "https://search.danawa.com/dsearch.php?query=ê²Œì´ë° ë…¸íŠ¸ë¶"
MAX_PAGES = 5
MAX_REVIEWS = 200
MAX_REVIEWS_PER_PRODUCT = 20 

# ì œí’ˆ ëª©ë¡ ì„ íƒì
PRODUCT_LINK_SELECTOR = 'a.click_log_product_standard_title_' 

# ë¦¬ë·° í…ìŠ¤íŠ¸ ì„ íƒì
REVIEW_TEXT_SELECTOR = 'div.atc' 

# 'ë”ë³´ê¸°' ë²„íŠ¼ ì„ íƒì
MORE_BUTTON_SELECTOR = 'button.btn_review_more'


# --- 1. ë“œë¼ì´ë²„ ì´ˆê¸°í™” í•¨ìˆ˜ ---
def init_driver():
    options = webdriver.ChromeOptions()
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

# --- 2. ì œí’ˆ ëª©ë¡ URL ìˆ˜ì§‘ í•¨ìˆ˜ (URL ê³ ìœ ì„± í™•ë³´) ---
def get_product_urls(driver, base_url, max_pages):
    urls = []
    print(">> ë‹¤ë‚˜ì™€ ì œí’ˆ ìƒì„¸ URL ìˆ˜ì§‘ ì‹œì‘...")
    
    for page in range(1, max_pages + 1):
        # base_url ì¸ìë¥¼ ì‚¬ìš©í•˜ì—¬ URL ìƒì„±
        list_url = f"{base_url}&page={page}" 
        driver.get(list_url)
        time.sleep(random.uniform(1, 2))
        
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, PRODUCT_LINK_SELECTOR))
            )
            links = driver.find_elements(By.CSS_SELECTOR, PRODUCT_LINK_SELECTOR)
            for link in links:
                href = link.get_attribute('href')
                
                if href and '/info/?pcode=' in href:
                    pcode_index = href.find('pcode=')
                    if pcode_index != -1:
                        pcode_value = href[pcode_index + 6:].split('&')[0]
                        unique_url = f"https://prod.danawa.com/info/?pcode={pcode_value}"
                        urls.append(unique_url)
            
            print(f"í˜ì´ì§€ {page}ì—ì„œ {len(urls)}ê°œ URL ìˆ˜ì§‘ ì¤‘...", end='\r')
            
        except Exception:
            break
            
    unique_urls = list(set(urls))
    print(f"\n>> ì´ {len(unique_urls)}ê°œì˜ ê³ ìœ  ì œí’ˆ URL ìˆ˜ì§‘ ì™„ë£Œ.")
    # ğŸš¨ ìˆ˜ì • ì™„ë£Œ: ì¤‘ë³µ ì œê±°ëœ unique_urlsë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return unique_urls 

# --- 3. ë™ì  ë¦¬ë·° ì¶”ì¶œ í•¨ìˆ˜ (ìŠ¤í¬ë¡¤ ë™ì‘ ë° ë¦¬ë·° íƒ­ íŠ¹ì • í´ë¦­) ---
def extract_dynamic_reviews(driver, product_url):
    reviews = []
    
    try:
        driver.get(product_url)
        # ì œí’ˆ ì œëª© ë¡œë”© í™•ì¸ (í˜ì´ì§€ ì§„ì… í™•ì¸)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, 'h3.prod_tit'))
        )
        title = driver.find_element(By.CSS_SELECTOR, 'h3.prod_tit').text
        
        # ğŸ’¡ ì¶”ê°€: ì œëª© í´ë¦¬ë‹ ë¡œì§
        if '\nVSê²€ìƒ‰í•˜ê¸°\nVSê²€ìƒ‰ ë„ì›€ë§' in title:
            title = title.replace('\nVSê²€ìƒ‰í•˜ê¸°\nVSê²€ìƒ‰ ë„ì›€ë§', '').strip()
        
        print(f"\n[ì œí’ˆ] {title} ìƒì„¸ í˜ì´ì§€ ì§„ì… ì„±ê³µ.")

        # 1. ìŠ¤í¬ë¡¤ ë™ì‘ ì¶”ê°€: ë¦¬ë·° íƒ­(ë“œë¡­ë‹¤ìš´ ë°”)ì´ ë‚˜íƒ€ë‚˜ë„ë¡ í™”ë©´ì„ ë‚´ë¦¼
        driver.execute_script("window.scrollBy(0, 800);") 
        print(f" 	âœ… 1. 800px ìŠ¤í¬ë¡¤ ì„±ê³µ. ë“œë¡­ë‹¤ìš´ ë¦¬ë·° íƒ­ í™œì„±í™” ì‹œë„.")
        time.sleep(2) 
        
        # 2-1. 'ì˜ê²¬/ë¦¬ë·°' íƒ­ í´ë¦­ (1ë‹¨ê³„: íƒ­ í™œì„±í™”)
        review_tab_xpath = "//h3[@class='tab_txt' and text()='ì˜ê²¬/ë¦¬ë·°']/parent::a"
        review_link = None
        try:
            review_link = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.XPATH, review_tab_xpath))
            )
            ActionChains(driver).move_to_element(review_link).click().perform()
            print(f" 	âœ… 2-1. 'ì˜ê²¬/ë¦¬ë·°' íƒ­ 1ì°¨ Action í´ë¦­ ì„±ê³µ (íƒ­ í™œì„±í™”).")
            time.sleep(3) 
            
        except Exception:
            print(f" 	âŒ 2-1. 'ì˜ê²¬/ë¦¬ë·°' íƒ­ í´ë¦­ ì‹¤íŒ¨! XPath '{review_tab_xpath}'ë¥¼ ì°¾ê±°ë‚˜ í´ë¦­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # 2-2. 'ì‡¼í•‘ëª° ìƒí’ˆë¦¬ë·°' íƒ­ í´ë¦­ (2ë‹¨ê³„: ë¦¬ë·° ë°ì´í„° ë¡œë“œ)
        SUB_REVIEW_TAB_XPATH = "//h4[@class='txt' and text()='ì‡¼í•‘ëª° ìƒí’ˆë¦¬ë·°']/parent::a"
        
        try:
            sub_review_link = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.XPATH, SUB_REVIEW_TAB_XPATH))
            )
            ActionChains(driver).move_to_element(sub_review_link).click().perform()
            
            print(f" 	âœ… 2-2. 'ì‡¼í•‘ëª° ìƒí’ˆë¦¬ë·°' íƒ­ (XPath) Action í´ë¦­ ì„±ê³µ (ë°ì´í„° ë¡œë“œ ì‹œë„).")
            time.sleep(3)
            
        except Exception:
            print(f" 	âŒ 2-2. 'ì‡¼í•‘ëª° ìƒí’ˆë¦¬ë·°' íƒ­ í´ë¦­ ì‹¤íŒ¨! XPath '{SUB_REVIEW_TAB_XPATH}'ë¥¼ ì°¾ê±°ë‚˜ í´ë¦­í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # ëŒ€ì²´ ë¡œì§ (Fallback)
            if review_link is not None:
                print(f" 	 	ğŸ’¡ ëŒ€ì•ˆ: 'ì˜ê²¬/ë¦¬ë·°' íƒ­ì„ í•œ ë²ˆ ë” ëˆŒëŸ¬ ë°ì´í„° ë¡œë“œë¥¼ ê°•ì œ ì‹œë„í•©ë‹ˆë‹¤.")
                try:
                    ActionChains(driver).move_to_element(review_link).click().perform()
                    print(f" 	 	âœ… ëŒ€ì•ˆ ì„±ê³µ: 'ì˜ê²¬/ë¦¬ë·°' íƒ­ ì¬í´ë¦­ ì„±ê³µ.")
                    time.sleep(3)
                except Exception:
                    print(f" 	 	âŒ ëŒ€ì•ˆ ì‹¤íŒ¨: 'ì˜ê²¬/ë¦¬ë·°' íƒ­ ì¬í´ë¦­ë„ ì‹¤íŒ¨.")
                    return []
            else:
                return []


        # 3. ë¦¬ë·° í…ìŠ¤íŠ¸ê°€ ì‹¤ì œë¡œ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        try:
            WebDriverWait(driver, 3).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, REVIEW_TEXT_SELECTOR))
            )
            print(f" 	âœ… 3. ë¦¬ë·° ì½˜í…ì¸  ë¡œë”© ì„±ê³µ. ì„ íƒì: '{REVIEW_TEXT_SELECTOR}'")
            time.sleep(2)
        except:
            print(f" 	âŒ 3. ë¦¬ë·° ì½˜í…ì¸  ë¡œë”© ì‹¤íŒ¨! ì„ íƒì '{REVIEW_TEXT_SELECTOR}'ì— í•´ë‹¹í•˜ëŠ” ìš”ì†Œê°€ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì„ íƒì ì˜¤ë¥˜)")
            return []

        # 4. 'ë”ë³´ê¸°' ë²„íŠ¼ ë°˜ë³µ í´ë¦­ ë¡œì§
        count = 0
        while len(reviews) < MAX_REVIEWS_PER_PRODUCT:
            current_elements = driver.find_elements(By.CSS_SELECTOR, REVIEW_TEXT_SELECTOR)
            if len(current_elements) >= MAX_REVIEWS_PER_PRODUCT:
                 break 
            
            try:
                more_button = WebDriverWait(driver, 3).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, MORE_BUTTON_SELECTOR))
                )
                ActionChains(driver).move_to_element(more_button).click().perform()
                count += 1
                time.sleep(1.5) 
            except:
                break 

        print(f" 	âœ… 4. 'ë”ë³´ê¸°' ë²„íŠ¼ {count}íšŒ Action í´ë¦­ ì™„ë£Œ.")

        # 5. ëª¨ë“  ë¡œë”©ëœ ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì œí•œ ì ìš©
        review_elements = driver.find_elements(By.CSS_SELECTOR, REVIEW_TEXT_SELECTOR)
        
        for el in review_elements:
            text = el.text.strip()
            if len(text) > 10 and len(reviews) < MAX_REVIEWS_PER_PRODUCT:
                reviews.append({"title": title, "text": text})

        print(f" 	âœ… 5. ìµœì¢… {len(reviews)}ê±´ì˜ ë¦¬ë·° ì¶”ì¶œ ì„±ê³µ (ì œí•œ: {MAX_REVIEWS_PER_PRODUCT}ê±´).")

    except Exception:
        pass
        
    return reviews

# --- 4. ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰ ë° íŒŒì¼ ì €ì¥ ---
if __name__ == "__main__":
    driver = init_driver()
    target_urls = get_product_urls(driver, BASE_SEARCH_URL, MAX_PAGES)
    
    all_reviews = []
    
    print(f"\nì´ {len(target_urls)}ê°œ ì œí’ˆ URL ê¸°ë°˜ìœ¼ë¡œ ë¦¬ë·° {MAX_REVIEWS}ê±´ ìˆ˜ì§‘ ëª©í‘œ (ì œí’ˆë‹¹ ìµœëŒ€ {MAX_REVIEWS_PER_PRODUCT}ê±´).")
    
    if len(target_urls) > 0:
        for url in target_urls:
            reviews = extract_dynamic_reviews(driver, url)
            all_reviews.extend(reviews)
            
            print(f"ìµœì¢… ìˆ˜ì§‘ëœ ë¦¬ë·°: {len(all_reviews)}ê±´", end='\r')
            
            if len(all_reviews) >= MAX_REVIEWS:
                print(f"\n>> ëª©í‘œ {MAX_REVIEWS}ê±´ ë‹¬ì„±! í¬ë¡¤ë§ ì¤‘ë‹¨.")
                break
            time.sleep(random.uniform(1, 2)) 
    
    driver.quit()
    
    if all_reviews:
        with open('documents.json', 'w', encoding='utf-8') as f:
            json.dump(all_reviews, f, ensure_ascii=False, indent=4) 
        print(f"\nâœ… 'documents.json' íŒŒì¼ ì €ì¥ ì™„ë£Œ. ì´ {len(all_reviews)}ê±´ ìˆ˜ì§‘.")
    else:
        print("\nâŒ ë¦¬ë·° ìˆ˜ì§‘ì— ìµœì¢… ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¦¬ë·° í…ìŠ¤íŠ¸/ë”ë³´ê¸° ë²„íŠ¼ ì„ íƒì í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")